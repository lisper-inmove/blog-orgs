#+TITLE: Deployment
#+DATE: 2023-09-28 16:35:17
#+DISPLAY: t
#+STARTUP: indent
#+OPTIONS: toc:10
#+AUTHOR: inmove
#+KEYWORDS: Deployment
#+CATEGORIES: Kubernates

* 什么是Deployment
一般情况下都不会直接使用Pod，转而使用 Deployment。

Deployment用于创建ReplicaSet，ReplicaSet由多个Pod组成。如果某个Pod失败，会自动创建一个新的Pod来替换它。
可以通过HPA自动调整Pod的数量。可以更轻松地更新应用，回滚到之前的版本，扩展应用等。

下面是一个用Deployment管理Nginx的例子。这里的template基本和Pod的yaml文件一致。

#+begin_src yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: nginx
  spec:
    selector:
      matchLabels:
        app: nginx
    replicas: 3  # 定义副本的数量
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 0
        maxSurge: 2
    template:
      metadata:
        labels:
          app: nginx
      spec:
        containers:
          - name: nginx     # 测试用版本1.14.2
            image: nginx
            imagePullPolicy: IfNotPresent
            ports:
              - containerPort: 80
#+end_src

* 滚动升级
#+begin_src shell
  k set image deployment/NAME CONTAINER-NAME=IMAGE:IMAGE-VERSION
  k edit deployment/NAME # 修改镜像
  k rollout status deployment/NAME # 查看更新日志
  k rollout undo deployment/NAME # 回滚到上一个版本
  k rollout history deployment/NAME # 更新历史
  k rollout pause deployment/NAME # 暂停当前更新
  k rollout resume deployment/NAME # 恢复更新
  k scale deployment/NAME --replicas N # 扩容或缩容
#+end_src
Deployment升级策略一共有两种
1. Recreate: 杀掉所有正在运行的Pod，然后创建新的。这种应该不会有人使用
2. RollingUpdate: 默认值，滚动更新
   1. maxUnavailable: 指定更新过程中，不可用Pod的数量上限，可以是数字，也可以是百分比。
   2. maxSurge: 指定更新过程中，Pod总数量超过期望副本数量的最大值.数字或百分比。

使用 --record 来记录更新命令。但是这个参数已经被标记为 deprecated，将来很可能被移除。

通过组合 maxUnavailable = 0, maxSurge = 观察当更新到1个Pod时可以使用暂停功能做到局部更新。也可能通过CronJob来监视Pod的数量，然后再自动触发暂停。

* HorizontalPodAutoscaler
自动扩缩容的机制。根据cpu利用率，内存使用或者自定义指标(如HTTP请求速率)，HPA可以自动的增加或减少Pod的副本数。
** 配置metrics
#+begin_src yaml
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    labels:
      k8s-app: metrics-server
    name: metrics-server
    namespace: kube-system
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      k8s-app: metrics-server
      rbac.authorization.k8s.io/aggregate-to-admin: "true"
      rbac.authorization.k8s.io/aggregate-to-edit: "true"
      rbac.authorization.k8s.io/aggregate-to-view: "true"
    name: system:aggregated-metrics-reader
  rules:
  - apiGroups:
    - metrics.k8s.io
    resources:
    - pods
    - nodes
    verbs:
    - get
    - list
    - watch
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    labels:
      k8s-app: metrics-server
    name: system:metrics-server
  rules:
  - apiGroups:
    - ""
    resources:
    - nodes/metrics
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - pods
    - nodes
    verbs:
    - get
    - list
    - watch
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    labels:
      k8s-app: metrics-server
    name: metrics-server-auth-reader
    namespace: kube-system
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: extension-apiserver-authentication-reader
  subjects:
  - kind: ServiceAccount
    name: metrics-server
    namespace: kube-system
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      k8s-app: metrics-server
    name: metrics-server:system:auth-delegator
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:auth-delegator
  subjects:
  - kind: ServiceAccount
    name: metrics-server
    namespace: kube-system
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    labels:
      k8s-app: metrics-server
    name: system:metrics-server
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:metrics-server
  subjects:
  - kind: ServiceAccount
    name: metrics-server
    namespace: kube-system
  ---
  apiVersion: v1
  kind: Service
  metadata:
    labels:
      k8s-app: metrics-server
    name: metrics-server
    namespace: kube-system
  spec:
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      k8s-app: metrics-server
  ---
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      k8s-app: metrics-server
    name: metrics-server
    namespace: kube-system
  spec:
    selector:
      matchLabels:
        k8s-app: metrics-server
    strategy:
      rollingUpdate:
        maxUnavailable: 0
    template:
      metadata:
        labels:
          k8s-app: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=4443
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --kubelet-insecure-tls
          image: dyrnq/metrics-server:v0.6.4
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            periodSeconds: 10
          name: metrics-server
          ports:
          - containerPort: 4443
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            initialDelaySeconds: 20
            periodSeconds: 10
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        serviceAccountName: metrics-server
        volumes:
        - emptyDir: {}
          name: tmp-dir
  ---
  apiVersion: apiregistration.k8s.io/v1
  kind: APIService
  metadata:
    labels:
      k8s-app: metrics-server
    name: v1beta1.metrics.k8s.io
  spec:
    group: metrics.k8s.io
    groupPriorityMinimum: 100
    insecureSkipTLSVerify: true
    service:
      name: metrics-server
      namespace: kube-system
    version: v1beta1
    versionPriority: 100

#+end_src
** 启动一个Nginx并为其设置HPA
#+begin_src yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: nginx
  spec:
    selector:
      matchLabels:
        app: nginx
    replicas: 2
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 2
        maxSurge: 10
    template:
      metadata:
        labels:
          app: nginx
      spec:
        containers:
          - name: nginx
            image: nginx
            imagePullPolicy: IfNotPresent
            ports:
              - containerPort: 80
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1"
                memory: "256Mi"
  ---
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: nginx-hpa
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: nginx
    minReplicas: 3
    maxReplicas: 10
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization

          # 单个pod的使用情况到了60%就会触发HPA
          averageUtilization: 60
#+end_src
** 测试HPA
用下面这条命令进到其中一个Pod中。
#+begin_src shell
  k exec -it nginx-b4f6db765-pgfkb -- /bin/bash
#+end_src

执行这个命令，可以多开几个窗口
#+begin_src shell
  for i in {1..100000};do curl 127.0.0.1;done
#+end_src

然后不停地观察hpa的信息，只要TARGETS超过了60%就会看到nginx的Pod又多了一个。
#+begin_src shell
  k get hpa
#+end_src
| NAME      | REFERENCE        | TARGETS | MINPODS | MAXPODS | REPLICAS | AGE |
|-----------|------------------|---------|---------|---------|----------|-----|
| nginx-hpa | Deployment/nginx | 49%/60% | 3       | 10      | 4        | 31m |
