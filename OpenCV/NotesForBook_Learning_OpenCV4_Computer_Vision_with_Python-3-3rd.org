#+TITLE: Notes for Learning OpenCV 4 Computer Vision with Python 3 3rd
#+DATE: 2025-05-07 22:46:22
#+DISPLAY: t
#+STARTUP: indent
#+OPTIONS: toc:10
#+AUTHOR: inmove
#+SUBTITLE: Reading notes for an OpenCV book
#+KEYWORDS: ImageConduct
#+CATEGORIES: OpenCV

* Chapter Two

An image is a multidimensional array, it has columns and rows of pixels, and each pixel has a value.
For different kinds of image data, the pixel value may be formatted in different ways.

1. grayscale image. Each pixel is represented by a single 8-bit integer. 0 ~ 255, 0 is black, 255 is white, and the in-between values are shades of gray.
   #+begin_src python :results output
     import numpy
     img = numpy.zeros((3, 3), dtype=numpy.uint8)
     print(img)
   #+end_src

   #+RESULTS:
   : [[0 0 0]
   :  [0 0 0]
   :  [0 0 0]]

2. blue-green-red: each pixel is represented by a three-element array, B, G and R. HSV will be represented in the same way, albeit with different value ranges.
   #+begin_src python :results output
     import numpy
     import cv2
     img = numpy.zeros((3, 3), dtype=numpy.uint8)
     img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
     print(img)
   #+end_src

   #+RESULTS:
   #+begin_example
   [[[0 0 0]
     [0 0 0]
     [0 0 0]]

    [[0 0 0]
     [0 0 0]
     [0 0 0]]

    [[0 0 0]
     [0 0 0]
     [0 0 0]]]
   #+end_example

3. HSV: Better for tasks like object detection and segmentation in computer vision.
   1. H(Hue): the type  of color, represented as an angle from 0° to 360°. Red ≈ 0°, Green ≈ 120°, Blue ≈ 240°
   2. S(Saturation): the intensity or purity of the color, ranging from 0 to 1 (0% to 100%)
   3. V(Value or Brightness): the brightness of the color, ranging from 0(black) to 1(full brightness)

Image must be a two-dimensional array, when we strip of outermost 2-dimensional of an image
1. for grayscale image, we get some independent numbers(1 channel), a number is a pixel.
2. for BGR image, we get some one-dimensional array(3 channel), an array is a pixel.

* Chapter Three
By default OpenCV uses the *BGR* color model to represent any image.

** HPFs and LPFs
HPFs(高通滤波) and LPFs(低通滤波)

HPFs is a filter that examines a region of an image and boosts the intensity of certain pixels based on the difference in the intensity of the surrounding pixels.
#+begin_src python
  [[0,     -0.25,    0],
   [-0.25, 1,        -0.25],
   [0,     -02.5,    0]]
#+end_src
Above is a kernel(卷积核). If a pixel stands out from the surrounding pixels, the resulting value will be high. This type of kernel represents a so-called high-boost filter, which is a type of HPF, and it's particularly effective in *edge detection*.
#+begin_src python
  import cv2
  import numpy as np
  from scipy import ndimage

  kernel_3x3 = np.array([
      [-1, -1, -1],
      [-1, 8, -1],
      [-1, -1, -1],
  ])

  kernel_5x5 = np.array([
      [-1, -1, -1, -1, -1],
      [-1, 1, 2, 1, -1],
      [-1, 2, 4, 2, -1],
      [-1, 1, 2, 1, -1],
      [-1, -1, -1, -1, -1],
  ])
  img = cv2.imread(
      "./Learning-OpenCV-4-Computer-Vision-with-Python-Third-Edition/images/statue_small.jpg",
      0,
  )

  k3 = ndimage.convolve(img, kernel_3x3)
  k5 = ndimage.convolve(img, kernel_5x5)

  # A LPF
  blurred = cv2.GaussianBlur(img, (17, 17), 0)
  # origin - LPF = HPF
  g_hpf = img - blurred

  cv2.imshow("3x3", k3)
  cv2.imshow("5x5", k5)
  cv2.imshow("blurred", blurred)
  cv2.imshow("g_hpf", g_hpf)
  cv2.waitKey()
  cv2.destroyAllWindows()
#+end_src

** Custom kernels - getting convoluted
*** Convolution matrix
It is a 2D array with an odd number of rows and columns. The central element corresponds to a pixel of interest, while the other elements correspond to the neighbors of this pixel.
Each element contains an integer or floating-point value, which is a weight that gets applied to an input pixel's value.
#+begin_src python
  [[-1, -1, -1],
   [-1, 9, -1],
   [-1, -1, -1]]
#+end_src

** Edge Detection
OpenCV provides many edge-finding filters, including *Laplacian* *Sobel* and *Scharr*. This filters are supposed to turn non-edge regions into black and turn edge regions into white or saturated(饱和的) colors.
However, they are prone to misidentifying noise as edges, this flow can be mitigated by *blurring* an image before trying to find its edges.

#+begin_src python
  import cv2


  def strokeEdges(src, dst, blurKsize=7, edgeKsize=5):
      if blurKsize >= 3:
          blurredSrc = cv2.medianBlur(src, blurKsize)
          graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)
      else:
          graySrc = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)

      # laplacian edge detect, brighten edge, darken none edge
      # set result back to graySrc
      cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize=edgeKsize)
      # 255 - graySrc: reverse edge detect image. brighten none edge, darken edge.
      # (1.0 / 255) * value: normalize reverse edge detect image as transparency value
      normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)

      # if image is (H, W, 3)
      # every channel will be (H, W)
      channels = cv2.split(src)
      for channel in channels:
          channel[:] = channel * normalizedInverseAlpha

      cv2.merge(channels, dst)

#+end_src

*** laplacian
The cv2.Laplacian() function in OpenCV performs Laplacian edge detection, which is based on the second-order derivatives of the image intensity.
It highlights regions of rapid intensity change, which typically correspond to edges.

The Laplacian is sensitive to noise. It’s recommended to apply a Gaussian blur before using it.

#+begin_src python
  Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst
#+end_src
ddepth: desired depth of the output image.

#+attr_formula:
#+begin_src latex
  \[
  \nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}
  \]
#+end_src
It measures how much the value at a point differs from its neighbors, large values typically mean an edge.

* Functions
** imread
imread returns an image in the BGR() color format

1. cv2.IMREAD_COLOR: default option, providing a 3-channel BGR image with an 8-bit value for each channel
2. cv2.IMREAD_GRAYSCALE: 8-bit grayscale image
3. cv2.IMREAD_ANYCOLOR: 8-bit BGR or 8-bit grayscale image, depending on the metadata in the file.
4. cv2.IMREAD_UNCHANGED: this reads all of the image data, including the alpha or transparency channel (if there is one) as a fourth channel.
5. cv2.IMREAD_ANYDEPTH: load an image in grayscale but keep its original bit depth, such as uint16 or uint32.
6. cv2.IMREAD_ANYDEPTH | cv2.IMREAD_COLOR: loads an image in BGR color at its original bit depth.
7. cv2.IMREAD_REDUCED_GRAYSCALE_2: loads an image in grayscale at half its original resolution. For example, if the file contains a 640 x 480 image, it is loaded as 320 x 240 image.
8. cv2.IMREAD_REDUCED_COLOR_2: loads an image in 8-bit-per-channel BGR color at half its original resolution
9. cv2.IMREAD_REDUCED_GRAYSCALE_4: 1/4
10. cv2.IMREAD_REDUCED_COLOR_4: 1/4
11. cv2.IMREAD_REDUCED_GRAYSCALE_8: 1/8
12. cv2.IMREAD_REDUCED_COLOR_8: 1/8

** filter2D
Applies any kernel or convolution matrix that we specify
#+begin_src python
  cv2.filter2D(
      src: numpy.ndarray,
      ddepth: int,
      kernel: numpy.ndarray,
      dst: numpy.ndarray = None,
      anchor: tuple = (-1, -1),
      delta: float = 0,
      borderType: int = cv2.BORDER_CONSTANT
  )
#+end_src
1. src: source image, it can be multi-channel
2. ddepth: specifies the deta type(depth) of the output image. bit depth(位深度,用于表示单个像素颜色的二进制位数)
   1. -1: means same as src
   2. cv2.CV_8U: unsigned 8-bit
   3. cv2.CV_16S: signed 16-bit
   4. cv2.CV_32F: float 32-bit
   5. cv2.CV_64F: float 64-bit
3. kernel: convolution kernel.
4. dst: output image of the same size and number of channels as src. if not provided, the result is returned.
5. anchor: position of the anchor point within the kerner. (-1, -1) means the anchor is at the kernel center.
6. delta: Adds a constant value to every pixel after convolution, helps in shifting the intensity values up or down.
7. borderType: specifies how the image borders are handled when the kernel overlaps the edge.
   1. cv2.BORDER_CONSTANT: pads with a constant value(default is 0)
   2. cv2.BORDER_REPLICATE: repeats the edge pixels.
   3. cv2.BORDER_REFLECT: reflects border pixels.
   4. cv2.BORDER_REFLECT_101: reflects without repeating edge pixels.
   5. cv2.BORDER_WRAP: wraps around the image
   6. cv2.BORDER_DEFAULT: same as cv2.BORDER_REFLECT_101

Here is an example.
#+begin_src python :results output
  import numpy as np
  import cv2

  # Create a 5x5 grayscale image (values from 0 to 255)
  img = np.array([
      [10, 10, 10, 10, 10],
      [10, 50, 50, 50, 10],
      [10, 50,100, 50, 10],
      [10, 50, 50, 50, 10],
      [10, 10, 10, 10, 10]
  ], dtype=np.uint8)

  # Define a Laplacian kernel for edge detection
  kernel = np.array([
      [-1, -1, -1],
      [-1,  8, -1],
      [-1, -1, -1]
  ], dtype=np.float32)

  # Apply the filter
  result = cv2.filter2D(src=img, ddepth=cv2.CV_64F, kernel=kernel)

  # Print results
  print("Original:\n", img)
  print("Filtered:\n", result)
#+end_src

#+RESULTS:
#+begin_example
Original:
 [[ 10  10  10  10  10]
 [ 10  50  50  50  10]
 [ 10  50 100  50  10]
 [ 10  50  50  50  10]
 [ 10  10  10  10  10]]
Filtered:
 [[-160. -160. -240. -160. -160.]
 [-160.  150.   70.  150. -160.]
 [-240.   70.  400.   70. -240.]
 [-160.  150.   70.  150. -160.]
 [-160. -160. -240. -160. -160.]]
#+end_example

cv2.BORDER_DEFAULT/cv2.BORDER_REFLECT_101:
#+begin_verse
将8与原图的第一个10对齐.kernel的第一行,第一列都没有与之对应的元素.
BORDER_REFLECT_101的扩充方式如下：
上方扩充: Row -1, 反射为 Row 1, 等于 [10, 50, 50, 50, 10]
左侧扩充: Column -1, 反射为 Colunm 1, 等于 [10, 50, 50, 50, 10] 垂直方向
左上角: Row -1, Column -1, 反射为 Row 1, Column 1 等于 50
#+end_verse

** Blur
*** medianBlur(中值滤波)
#+begin_src python
  cv2.medianBlur(src, ksize) -> dst
#+end_src
ksize: size of kernel, must be an odd number and bigger than 1
dst: output image, its types is same with src

Principle:
1. Sampling from neighborhood for every pixel
2. Sort all neighborhoods
3. Use the middle value to replace the pixel

Used to remove noise, good effective for salt-and-pepper(椒盐噪声,black spots and white spots) noise especially.

*** meanBlur(均值滤波)
#+begin_src python
  cv2.blur(src, ksize) -> dst
#+end_src

Piinciple:
1. Define a window for every pixel, window size is ksize x ksize.
2. Calculate average value
3. Use the average value to replace the center pixel

Used to remove noise, good effective for light noise, it is not sensitive for extreme value, details and egde will be vague(模糊).

*** GaussianBlur
#+begin_src python
  cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY, [borderType]]])
#+end_src
ksize: sizeof kernel, must be odd
sigmaX: standard deviation(标准差) for x axis, always set to 0, OpenCV will calculate it using ksize.
sigmaY: standard deviation for y axis, in most cases same as sigmaX
borderType: fill type for border

Principle:
Use a weight matrix(kernel) to cover every pixel one by one, calculate weighing average value.

#+attr_formula:
#+begin_src latex
  \[
  G(x, y) = \frac{1}{2\pi\sigma^2} \exp\left( -\frac{x^2 + y^2}{2\sigma^2} \right)
  \]
#+end_src
σ: standard deviation, degree of vague, *bigger σ more vague*.
exp: exponent function
x,y: relative distance to center pixel.

*** compare three blur methods
| Name         | Remove Noise | Keep edge | Blur level |
| medianBlur   |            4 |         4 |          1 |
| meanBlur     |            2 |         1 |          4 |
| GaussianBlur |            2 |         2 |          3 |
