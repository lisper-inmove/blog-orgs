#+TITLE: Notes for Learning OpenCV 4 Computer Vision with Python 3 3rd
#+DATE: 2025-05-07 22:46:22
#+DISPLAY: t
#+STARTUP: indent
#+OPTIONS: toc:10
#+AUTHOR: inmove
#+SUBTITLE: Reading notes for an OpenCV book
#+KEYWORDS: ImageConduct
#+CATEGORIES: OpenCV

* Codes in Book
[[github.com:PacktPublishing/Learning-OpenCV-4-Computer-Vision-with-Python-Third-Edition.git][Codes]]

Images in this note are under image folder of the repo.

* Chapter Two

An image is a multidimensional array, it has columns and rows of pixels, and each pixel has a value.
For different kinds of image data, the pixel value may be formatted in different ways.

1. grayscale image. Each pixel is represented by a single 8-bit integer. 0 ~ 255, 0 is black, 255 is white, and the in-between values are shades of gray.
   #+begin_src python :results output
     import numpy
     img = numpy.zeros((3, 3), dtype=numpy.uint8)
     print(img)
   #+end_src

   #+RESULTS:
   : [[0 0 0]
   :  [0 0 0]
   :  [0 0 0]]

2. blue-green-red: each pixel is represented by a three-element array, B, G and R. HSV will be represented in the same way, albeit with different value ranges.
   #+begin_src python :results output
     import numpy
     import cv2
     img = numpy.zeros((3, 3), dtype=numpy.uint8)
     img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
     print(img)
   #+end_src

   #+RESULTS:
   #+begin_example
   [[[0 0 0]
     [0 0 0]
     [0 0 0]]

    [[0 0 0]
     [0 0 0]
     [0 0 0]]

    [[0 0 0]
     [0 0 0]
     [0 0 0]]]
   #+end_example

3. HSV: Better for tasks like object detection and segmentation in computer vision.
   1. H(Hue): the type  of color, represented as an angle from 0° to 360°. Red ≈ 0°, Green ≈ 120°, Blue ≈ 240°
   2. S(Saturation): the intensity or purity of the color, ranging from 0 to 1 (0% to 100%)
   3. V(Value or Brightness): the brightness of the color, ranging from 0(black) to 1(full brightness)

Image must be a two-dimensional array, when we strip of outermost 2-dimensional of an image
1. for grayscale image, we get some independent numbers(1 channel), a number is a pixel.
2. for BGR image, we get some one-dimensional array(3 channel), an array is a pixel.

* Chapter Three
By default OpenCV uses the *BGR* color model to represent any image.

** HPFs and LPFs
HPFs(高通滤波) and LPFs(低通滤波)

HPFs is a filter that examines a region of an image and boosts the intensity of certain pixels based on the difference in the intensity of the surrounding pixels.
#+begin_src python
  [[0,     -0.25,    0],
   [-0.25, 1,        -0.25],
   [0,     -02.5,    0]]
#+end_src
Above is a kernel(卷积核). If a pixel stands out from the surrounding pixels, the resulting value will be high. This type of kernel represents a so-called high-boost filter, which is a type of HPF, and it's particularly effective in *edge detection*.
#+begin_src python
  import cv2
  import numpy as np
  from scipy import ndimage

  kernel_3x3 = np.array([
      [-1, -1, -1],
      [-1, 8, -1],
      [-1, -1, -1],
  ])

  kernel_5x5 = np.array([
      [-1, -1, -1, -1, -1],
      [-1, 1, 2, 1, -1],
      [-1, 2, 4, 2, -1],
      [-1, 1, 2, 1, -1],
      [-1, -1, -1, -1, -1],
  ])
  img = cv2.imread(
      "./Learning-OpenCV-4-Computer-Vision-with-Python-Third-Edition/images/statue_small.jpg",
      0,
  )

  k3 = ndimage.convolve(img, kernel_3x3)
  k5 = ndimage.convolve(img, kernel_5x5)

  # A LPF
  blurred = cv2.GaussianBlur(img, (17, 17), 0)
  # origin - LPF = HPF
  g_hpf = img - blurred

  cv2.imshow("3x3", k3)
  cv2.imshow("5x5", k5)
  cv2.imshow("blurred", blurred)
  cv2.imshow("g_hpf", g_hpf)
  cv2.waitKey()
  cv2.destroyAllWindows()
#+end_src

** Custom kernels - getting convoluted
*** Convolution matrix
It is a 2D array with an odd number of rows and columns. The central element corresponds to a pixel of interest, while the other elements correspond to the neighbors of this pixel.
Each element contains an integer or floating-point value, which is a weight that gets applied to an input pixel's value.
#+begin_src python
  [[-1, -1, -1],
   [-1, 9, -1],
   [-1, -1, -1]]
#+end_src

** Edge Detection
OpenCV provides many edge-finding filters, including *Laplacian* *Sobel* and *Scharr*. This filters are supposed to turn non-edge regions into black and turn edge regions into white or saturated(饱和的) colors.
However, they are prone to misidentifying noise as edges, this flow can be mitigated by *blurring* an image before trying to find its edges.

#+begin_src python
  import cv2


  def strokeEdges(src, dst, blurKsize=7, edgeKsize=5):
      if blurKsize >= 3:
          blurredSrc = cv2.medianBlur(src, blurKsize)
          graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)
      else:
          graySrc = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)

      # laplacian edge detect, brighten edge, darken none edge
      # set result back to graySrc
      cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize=edgeKsize)
      # 255 - graySrc: reverse edge detect image. brighten none edge, darken edge.
      # (1.0 / 255) * value: normalize reverse edge detect image as transparency value
      normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)

      # if image is (H, W, 3)
      # every channel will be (H, W)
      channels = cv2.split(src)
      for channel in channels:
          channel[:] = channel * normalizedInverseAlpha

      cv2.merge(channels, dst)

#+end_src

*** laplacian
The cv2.Laplacian() function in OpenCV performs Laplacian edge detection, which is based on the second-order derivatives of the image intensity.
It highlights regions of rapid intensity change, which typically correspond to edges.

The Laplacian is sensitive to noise. It’s recommended to apply a Gaussian blur before using it.

#+begin_src python
  Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst
#+end_src
ddepth: desired depth of the output image.

#+attr_formula:
#+begin_src latex
  \[
  \nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}
  \]
#+end_src
It measures how much the value at a point differs from its neighbors, large values typically mean an edge.
*** Edge detection with Canny
#+begin_src python
  cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) → edges
#+end_src
1. threshold1: Used edge connect(low threshold)
2. threshold2: Used edge detect(high threshold)
3. apertureSize: Sobel operator, default is 3, must be odd number
4. L2gradient: Use L2 norm to calculate gradient or not, default is false use L1.

Five Step process:
1. Denoise the image with Gaussian filter
2. Calculate the gradients
3. Apply NMS on the edges
4. Apply a double threshed to all the detected edges to eliminate any false positives.
5. Analyze all the edges and their connection to each other to keep the real edges and discard the weak ones.

It is based on *Canny Edge Detection Algorithm*, it can detect intensity gradient in image, always used to *Extract Sketch of Object*.

** Contour Detection
#+begin_src python
  import cv2
  import numpy as np

  img = np.zeros((200, 200), dtype=np.uint8)
  img[50:150, 50:150] = 255
  # 将大于阈值(127)的全部设置为255，小于等于全部设置为0
  ret, thresh = cv2.threshold(img, 127, 255, 0)
  # 找出所有的轮廓,hierarchy为轮廓的层级关系
  contours, hierarchy = cv2.findContours(
      thresh,
      cv2.RETR_TREE,  # 建立完整的轮廓层级
      cv2.CHAIN_APPROX_SIMPLE,  # 压缩 水平，垂直和对角线 的轮廓点，仅保留端点
  )

  # 将灰阶图转在BGR格式
  color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
  # 将轮廓以绿色画在BGR图上
  img = cv2.drawContours(color, contours, -1, (0, 255, 0), 2)
  cv2.imshow("contours", color)
  cv2.waitKey()
  cv2.destroyAllWindows()
#+end_src

#+begin_src python
  import cv2
  import numpy as np

  img = cv2.pyrDown(cv2.imread("./images/hammer.jpg", cv2.IMREAD_UNCHANGED))
  ret, thresh = cv2.threshold(
      cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),
      127,
      255,
      cv2.THRESH_BINARY,
  )

  contours, hier = cv2.findContours(
      thresh,
      cv2.RETR_EXTERNAL,
      cv2.CHAIN_APPROX_SIMPLE,
  )


  for c in contours:
      # vertical bounding rect
      x, y, w, h = cv2.boundingRect(c)
      cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)

      # min area rect
      rect = cv2.minAreaRect(c)
      box = cv2.boxPoints(rect)
      box = np.int0(box)
      cv2.drawContours(img, [box], 0, (0, 0, 255), 3)

      # bounding circle
      (x, y), radius = cv2.minEnclosingCircle(c)
      center = (int(x), int(y))
      radius = int(radius)
      img = cv2.circle(img, center, radius, (0, 255, 0), 2)

  cv2.drawContours(img, contours, -1, (255, 0, 0), 1)
  cv2.imshow("contours", img)

  cv2.waitKey()
  cv2.destroyAllWindows()
#+end_src

* Functions
** imread
#+begin_src python
  imread(filepath, flags)
#+end_src

flags's value as follows:
1. cv2.IMREAD_COLOR: default option, providing a 3-channel BGR image with an 8-bit value for each channel
2. cv2.IMREAD_GRAYSCALE: 8-bit grayscale image
3. cv2.IMREAD_ANYCOLOR: 8-bit BGR or 8-bit grayscale image, depending on the metadata in the file.
4. cv2.IMREAD_UNCHANGED: this reads all of the image data, including the alpha or transparency channel (if there is one) as a fourth channel.
5. cv2.IMREAD_ANYDEPTH: load an image in grayscale but keep its original bit depth, such as uint16 or uint32.
6. cv2.IMREAD_ANYDEPTH | cv2.IMREAD_COLOR: loads an image in BGR color at its original bit depth.
7. cv2.IMREAD_REDUCED_GRAYSCALE_2: loads an image in grayscale at half its original resolution. For example, if the file contains a 640 x 480 image, it is loaded as 320 x 240 image.
8. cv2.IMREAD_REDUCED_COLOR_2: loads an image in 8-bit-per-channel BGR color at half its original resolution
9. cv2.IMREAD_REDUCED_GRAYSCALE_4: 1/4
10. cv2.IMREAD_REDUCED_COLOR_4: 1/4
11. cv2.IMREAD_REDUCED_GRAYSCALE_8: 1/8
12. cv2.IMREAD_REDUCED_COLOR_8: 1/8

** imwrite
#+begin_src python
  imwrite(savepath, src)
#+end_src
filetype is decided by savepath's suffix.
** filter2D
Applies any kernel or convolution matrix that we specify
#+begin_src python
  cv2.filter2D(
      src: numpy.ndarray,
      ddepth: int,
      kernel: numpy.ndarray,
      dst: numpy.ndarray = None,
      anchor: tuple = (-1, -1),
      delta: float = 0,
      borderType: int = cv2.BORDER_CONSTANT
  )
#+end_src
1. src: source image, it can be multi-channel
2. ddepth: specifies the deta type(depth) of the output image. bit depth(位深度,用于表示单个像素颜色的二进制位数)
   1. -1: means same as src
   2. cv2.CV_8U: unsigned 8-bit
   3. cv2.CV_16S: signed 16-bit
   4. cv2.CV_32F: float 32-bit
   5. cv2.CV_64F: float 64-bit
3. kernel: convolution kernel.
4. dst: output image of the same size and number of channels as src. if not provided, the result is returned.
5. anchor: position of the anchor point within the kerner. (-1, -1) means the anchor is at the kernel center.
6. delta: Adds a constant value to every pixel after convolution, helps in shifting the intensity values up or down.
7. borderType: specifies how the image borders are handled when the kernel overlaps the edge.
   1. cv2.BORDER_CONSTANT: pads with a constant value(default is 0)
   2. cv2.BORDER_REPLICATE: repeats the edge pixels.
   3. cv2.BORDER_REFLECT: reflects border pixels.
   4. cv2.BORDER_REFLECT_101: reflects without repeating edge pixels.
   5. cv2.BORDER_WRAP: wraps around the image
   6. cv2.BORDER_DEFAULT: same as cv2.BORDER_REFLECT_101

Here is an example.
#+begin_src python :results output
  import numpy as np
  import cv2

  # Create a 5x5 grayscale image (values from 0 to 255)
  img = np.array([
      [10, 10, 10, 10, 10],
      [10, 50, 50, 50, 10],
      [10, 50,100, 50, 10],
      [10, 50, 50, 50, 10],
      [10, 10, 10, 10, 10]
  ], dtype=np.uint8)

  # Define a Laplacian kernel for edge detection
  kernel = np.array([
      [-1, -1, -1],
      [-1,  8, -1],
      [-1, -1, -1]
  ], dtype=np.float32)

  # Apply the filter
  result = cv2.filter2D(src=img, ddepth=cv2.CV_64F, kernel=kernel)

  # Print results
  print("Original:\n", img)
  print("Filtered:\n", result)
#+end_src

#+RESULTS:
#+begin_example
Original:
 [[ 10  10  10  10  10]
 [ 10  50  50  50  10]
 [ 10  50 100  50  10]
 [ 10  50  50  50  10]
 [ 10  10  10  10  10]]
Filtered:
 [[-160. -160. -240. -160. -160.]
 [-160.  150.   70.  150. -160.]
 [-240.   70.  400.   70. -240.]
 [-160.  150.   70.  150. -160.]
 [-160. -160. -240. -160. -160.]]
#+end_example

cv2.BORDER_DEFAULT/cv2.BORDER_REFLECT_101:
#+begin_verse
将8与原图的第一个10对齐.kernel的第一行,第一列都没有与之对应的元素.
BORDER_REFLECT_101的扩充方式如下：
上方扩充: Row -1, 反射为 Row 1, 等于 [10, 50, 50, 50, 10]
左侧扩充: Column -1, 反射为 Colunm 1, 等于 [10, 50, 50, 50, 10] 垂直方向
左上角: Row -1, Column -1, 反射为 Row 1, Column 1 等于 50
#+end_verse

** split and merge
split: If your image is (H, W, 3), you will get three images of (H, W)
#+begin_src python
  cv2.split(src)
#+end_src

merge: If you have three grayscale images, you can merge them one for blue, one for green and one for red.
#+begin_src python
  cv2.merge([b, g, r])
#+end_src
** Blur
*** medianBlur(中值滤波)
#+begin_src python
  cv2.medianBlur(src, ksize) -> dst
#+end_src
ksize: size of kernel, must be an odd number and bigger than 1
dst: output image, its types is same with src

Principle:
1. Sampling from neighborhood for every pixel
2. Sort all neighborhoods
3. Use the middle value to replace the pixel

Used to remove noise, good effective for salt-and-pepper(椒盐噪声,black spots and white spots) noise especially.

*** meanBlur(均值滤波)
#+begin_src python
  cv2.blur(src, ksize) -> dst
#+end_src

Piinciple:
1. Define a window for every pixel, window size is ksize x ksize.
2. Calculate average value
3. Use the average value to replace the center pixel

Used to remove noise, good effective for light noise, it is not sensitive for extreme value, details and egde will be vague(模糊).

*** GaussianBlur
#+begin_src python
  cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY, [borderType]]])
#+end_src
ksize: sizeof kernel, must be odd
sigmaX: standard deviation(标准差) for x axis, always set to 0, OpenCV will calculate it using ksize.
sigmaY: standard deviation for y axis, in most cases same as sigmaX
borderType: fill type for border

Principle:
Use a weight matrix(kernel) to cover every pixel one by one, calculate weighing average value.

#+attr_formula:
#+begin_src latex
  \[
  G(x, y) = \frac{1}{2\pi\sigma^2} \exp\left( -\frac{x^2 + y^2}{2\sigma^2} \right)
  \]
#+end_src
σ: standard deviation, degree of vague, *bigger σ more vague*.
exp: exponent function
x,y: relative distance to center pixel.

*** compare three blur methods
| Name         | Remove Noise | Keep edge | Blur level |
| medianBlur   |            4 |         4 |          1 |
| meanBlur     |            2 |         1 |          4 |
| GaussianBlur |            2 |         2 |          3 |
** threshold
#+begin_src python
  retval, dst = cv2.threshold(src, thresh, maxval, type)
#+end_src
src: input grayscale image, must be sigle-channel 8-bit or 32-bit
thresh: the threshold value to classify pixel values
maxval: the value to assign if pixel value is more than the threshold depending on the type
type:
    cv2.THRESH_BINARY: pixel > thresh ? maxval : 0
    cv2.THRESH_BINARY_INV: inverse binary
    cv2.THRESH_TRUNC: pixel > thresh ? thresh : keep
    cv2.THRESH_TOZERO: pixel > thresh ? keep : 0
    cv2.THRESH_TOZERO_INV
    cv2.THRESH_OTSU: Otsu's method, automatically determines optimal threshold. When type is OTSU, parameter thresh is ignored.
** findContours
#+begin_src python
  contours, hierarchy = cv2.findContours(image, mode, method)
#+end_src
image: binary image, usually from cv2.threshold or cv2.Canny
mode:
    cv2.RETR_EXTERNAL: retrieves only the extreme outer contours
    cv2.RETR_LIST: retrieves all contours without any hierarchy
    cv2.RETR_TREE: retrieves all contours with full hierarchy of nested contours
    cv2.RETR_CCOMP: retrieves all contours and organizes them into a 2-level hierarchy.
method:
    cv2.CHAIN_APPROX_NONE: stores all points of the contour
    cv2.CHAIN_APPROX_SIMPLE: removes all redundant points and compresses the contours, saving memory.
returns:
    contours: A list of contour points, Each contour is an array of (x, y)
    hierarchy: Describes the parent-child relationships between contours.

** pyrDown
Used to reduce/increase the size of an image by half in both width and height, using *Gaussing pyramid downsampling*, this method is smoother and less aliasing-prone than simple resizing.

#+begin_src python
  dst = cv2.pyrDown(src[, dstize[, borderType]])
  dst = cv2.pyrUp(src[, dstize[, borderType]])
#+end_src
dstsize: default is src.shape / 2

** boundingRect
Calculate the smallest upright(axis-aligned) rectangle that fully contains a contour in image
#+begin_src python
  x, y, w, h = cv2.boundingRect(contour)
#+end_src
** minAreaRect
Minimal rectangle that fully contains a contour in the image
#+begin_src python
  ((cx, cy), (w, h), angle) = cv2.minAreaRect(contour)
#+end_src
** boxPoints
Get four points from a rect
#+begin_src python
  box = cv2.boxPoints(rect)
#+end_src
** drawContours
Draw contours found by cv2.findContours
#+begin_src python
  cv2.drawContours(image, contours, contourIdx, color, thickness)
#+end_src
contourIdx: draw a specific contour, based on 0. -1 to draw all contours.
** minEncolsingCircle
Find the smallest circle that completely encloses a given contour or set of 2D points.
#+begin_src python
  (x, y), radius = cv2.minEnclosingCircle(pts)
#+end_src
points: A contour or a list of 2D points.
** draw shapes
*** cv2.line
#+begin_src python
  cv2.line(src, pt1, pt2, color, thickness)
#+end_src
*** cv2.rectangle
#+begin_src python
  cv2.rectangle(src, pt1, pt2, color, thiness)
#+end_src
*** cv2.circle
#+begin_src python
  cv2.circle(src, center, radius, color, thickness)
#+end_src
*** cv2.ellipse
#+begin_src python
  cv2.ellipse(src, center, axes, angle, startAngle, endAngle, color, thickenss, lineType=cv2.LINE_AA, shift)
#+end_src
axes: (a, b), length of major and minor axes (half-widths)
angle: rotation angle of the ellipse in degress
startAngle: starting angle of the arc in degress
endAngle: ending angle of the arc
lineType:
    LINE_4: 4-connected line (uses 4-neighbor pixels, fast but lower quality)
    LINE_8: 8-connected line
    LINE_AA: Anti-aliased line(smooth edges, best quality, slower)

*** cv2.polylines
#+begin_src python
  cv2.polylines(src, [pts], isClosed, color, thickness)
#+end_src
*** cv2.fillPoly
#+begin_src python
  cv2.fillPoly(img, [pts], color)
#+end_src
*** cv2.putText
#+begin_src python
  cv2.putText(img, "text", org, font, scale, color, thickness)
#+end_src
